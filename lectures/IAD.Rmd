---
title: "Интеллектуальный анализ данных"
subtitle: "Описание и программа курса"
author: "Храмов Д.А."
date: "29.02.2020"
output:
  html_document:
    toc: true
---


Курс посвящен анализу данных. У этой дисциплины много названий: интеллектуальный анализ данных, data mining, big data, ... — во всех вариантах присутствуют данные, с которыми нужно что-то сделать. Обрабатывать данные будет компьютер. Наша задача заключается в том, чтобы научить его это делать. Отсюда еще одно из названий дисциплины — машинное обучение. Нам предстоит создавать и обучать модели, которые в итоге станут компьютерными программами и позволят обнаруживать в данных ранее неизвестные закономерности, выделять объекты или классы объектов, прогнозировать развитие ситуации, рекомендовать варианты решения проблемы и помогать выбрать из них самый подходящий. Все это программы будут делать уже без нашего участия. Таким образом, анализ данных относится к методам искусственного интеллекта.

С результатами работы методов анализа данных мы сталкиваемся ежедневно, и сфера их применения постоянно расширяется. Данных становится все больше, так что интересные задачи найдутся всем. В мире растет потребность в специалистах в области анализа данных и машинного обучения.

Математическую основу анализа данных составляют методы теории вероятностей, математической статистики, линейной алгебры и оптимизации. Мы старались свести применение математики к разумному минимуму. Уровень сложности примерно соответствует 2—3-му курсам естественнонаучных специальностей современного университета.

**Итоговая оценка** = 0.8 `*` оценка за лабораторные + 0.2 `*` оценка на экзамене (зачете).

**Материалы курса:** https://github.com/dkhramov/iad_2020


# Лекции

## 1. Знакомство с анализом данных и R

Чем занимается интеллектуальный анализ данных. Почему стоит заниматься анализом данных. 

Инструментарий: пакет R. Установка R и среды разработки RStudio. Поиск информации по R. Литература, ссылки и видеокурсы. Курсы анализа данных, ориентированные на применение других языков программирования.

Пакет RMarkdown для составления отчетов о работе. Синтаксис Markdown. Pandoc. YAML. Оформление формул. Вставка "живого" кода в документ. Виды создаваемых документов.


## 2. Разведочный анализ данных

Типы данных (статистические шкалы) и как они реализованы в R. Имена переменных R. Векторы, списки и таблицы. Доступ к элементам. Создание/удаление. Факторы. Класс и структура переменных. Работа с переменными в RStudio. Построение графиков.

Генеральная совокупность и выборка. Меры центральной тенденции: среднее, медиана. Влияние выбросов. Квантили. Функция summary. Меры разброса: дисперсия, стандартное отклонение, межквартильное расстояние.

Разведочный анализ данных. Поиск поддельных купюр в наборе данных Swiss Bank Notes. Загрузка данных. Знакомство с данными, проверка на пропуски. Гистограмма и для чего она служит. Диаграмма рассеивания и матрица диаграмм рассеивания. Боксплот (boxplot) — как строить и зачем нужен. Основные функции, используемые в разведочном анализе данных.

Обнаружение и обработка пропусков в данных. Бимодальное распределение. Какую меру использовать для оценки населения типичного города. Преобразование статистического распределения. Обнаружение и обработка выбросов.


## 3. Кластерный анализ. Иерархическая кластеризация

Терминология и постановка задачи. Где используется кластерный анализ. Кластеризация и классификация. Идея метода. Расстояние между точками-объектами. Расстояние между кластерами. Примеры кластеров. Задачи аналитика в кластерном анализе. Способы стандартизации переменных. Выбор расстояния между кластерами разных видов. Интерпретация результатов кластерного анализа.

Алгоритм иерархического кластерного анализа. Построение дендрограммы. Работа функции hclust. Где на дендрограмме кластеры? График "каменистая осыпь" ("локоть"). 

Сегментация потребителей безалкогольных напитков. Кластеризация ирисов.


## 4. Кластерный анализ. Метод k-средних 

Алгоритм k-средних. Особенности метода k-средних. Выбор начального расположения центров кластеров. Определение числа кластеров k. Автоматизация поиска k (пакет NbClust).

Математическая модель k-means. Внутрикластерная сумма квадратов.

Сегментация потребителей безалкогольных напитков. Координаты центров кластеров — основной источник вдохновения для интерпретации. Визуализация результатов при помощи многомерного шкалирования.

Потребление белков в Европе. Влияние климата.

Недостатки иерархической кластеризации и k-средних. Алгоритмы кластеризации на основе плотности: метод DBSCAN. Описание алгоритма. Выбор параметров.


## 5. Проверка статистических гипотез

Понятие о статистической гипотезе. Виды и примеры гипотез. Алгоритм проверки статистических гипотез. Нулевая и альтернативная гипотезы. Проверка гипотезы о среднем. Статистический критерий и статистика критерия. Уровень значимости $\alpha$. Область принятия гипотезы и критическая область. $p$-значение. Формулирование вывода по результатам проверки гипотезы. Односторонние и двусторонние статистические критерии. Ошибки 1-го и 2-го рода, их связь с выбором уровня значимости. 

Случай двух выборок. Большие выборки (нормальное распределение) и малые выборки (распределение Стьюдента).

Проверка гипотезы о нормальности распределения случайной величины. Критерий Шапиро-Уилка. Критерий Колмогорова-Смирнова с поправкой Лиллиефорса. Рекомендации по применению критериев. Прагматический подход к проверке нормальности распределения.


## 6. Корреляция и регрессия

Ковариация. Коэффициент корреляции Пирсона. Направления связи. Сила корреляции. Зависимость налогов от площади дома при оценке недвижимости в Альбукерке. Коэффициент корреляции и независимость переменных. Квартет Анскомба. Связанность и причинная обусловленность, типичные ошибки при изучении связи между двумя явлениями. Функции для расчета корреляции в R.

Связь между номинативными переменными, коэффициент корреляции Крамера.

Регрессия. Модель линейной регрессии. Геометрическая идея решения. Функция потерь. Поиск коэффициентов линейной регрессии, метод наименьших квадратов.

Простая линейная регрессия. Функция lm. 

Оценка качества регрессии (MSE, RMSE). Коэффициент детерминации $R^2$, его интерпретации. Ограничения на область применения $R^2$.

Диагностика модели (summary). Этапы линейной регрессии в R.

Квадратичная аппроксимация (эксперимент Галилея).

Формулы (formula).


## 7. Многомерная линейная регрессия

Уравнения многомерной линейной регрессии. Прогноз цен на недвижимость в недвижимость в г. Альбукерке. (Мульти)коллинеарность, как ее выявить. Способы корректировки моделей. Цены на женские кольца с бриллиантами. Выбор информативных переменных.

Теорема Гаусса-Маркова: ее условия, что она дает и последствия нарушения ее ограничений. 

Анализ остатков. Вес новорожденного. Tolerance и VIF. Проверка постоянства дисперсий остатков. Коррекция моделей при отклонениях распределения остатков от нормального. Расстояние Кука и рычаг (leverage).

Ложная корреляция временных рядов.

Проблемы вычисления коэффициентов регрессии. Регуляризация, что она дает. Алгоритмы регрессии с регуляризацией.


## 8. Прогнозирование временных рядов

Прогноз, виды прогностических моделей. Чего следует ожидать от прогноза? Выявление аномалий.

Временной ряд. Примеры использования прогнозирования временных рядов. Составляющие временного ряда (тренд, сезонность, ошибка). Аддитивная и мультипликативная сезонность. Логарифмирование — прием для преобразования мультипликативной сезонности в аддитивную.

Прогнозирование на основе линейной регрессионной модели с сезонными (индикаторными) переменными. Порядок работы с временным рядом. Прогнозирование пассажирских авиаперевозок. Тренд. Сезонные составляющие. Смена характера ряда. Наличие выбросов. Ловушка индикаторных переменных и как с ней справляться. Прогноз продаж красного вина в Австралии, параболический тренд.

Недостатки применения линейной регрессии в прогнозировании временных рядов. Экспоненциальное сглаживание. Метод Холта-Уинтерса (Holt-Winters), модели с мультипликативной и аддитивной сезонностью. Локальный тренд, локальная сезонность. Прогнозирование международных авиаперевозок методом Холта-Уинтерса.

Визуализация составляющих временного ряда.

Сравнение экспоненциального сглаживания и линейной регрессии в прогнозировании временных рядов.

Метрики ошибок прогноза. Оценка качества модели сравнением с базовой моделью, выбор метода прогнозирования. Прогноз продаж пива в Австралии.


## 9. Классификация. Метод k ближайших соседей. Кроссвалидация

Обучение с учителем и без учителя. Задача классификации (распознавание образов), ее сходство и отличия от задач кластеризации и регрессии.

Метод k ближайших соседей (kNN). Состоятельность метода. Ленивое обучение. Стандартизация признаков. Необходимость отбора признаков. Определение числа ближайших соседей. Пакеты для kNN в R. Классификация ирисов. Создание обучающей и тестовой выборок. Оценка точности классификации: матрица неточностей. Другие применения kNN. Прогнозирование продаж нового сорта пива.

Схема работы в пакете caret. Прогноз цен на недвижимость в г. Бостон.

Проблема чрезмерной подгонки/переобучения (overfitting). Кроссвалидация (перекрестная проверка). Метод тестового множества. Метод исключенных наблюдений (leave-one-out cross validation). k-кратная кроссвалидация (k-fold кроссвалидация). Применения кроссвалидации.

Классификация вин в пакете caret.


## 10. Классификация. Деревья классификации и регрессии (CART)

Деревья классификации и регрессии (CART): алгоритм и его особенности. Бинарная классификация. Геометрическое представление метода. Представление в виде набора логических правил. 

Элементы дерева: узлы, родители и потомки, листья. Библиотека rpart. Разновидности метода: oblique trees, oblivious trees 

Как строить разделяющие гиперплоскости. Меры чистоты узла (impurity): индекс Джини, энтропия. Правила остановки обучения дерева. Задача кредитного скоринга. Визуализация деревьев: библиотеки rpart.plot и rattle.

Проблемы деревьев классификации. Борьба с переобучением. Обрезка деревьев (pruning).

Классификация вин с помощью CART. Оценка влиятельности переменных.


## 11. Ансамбли моделей

Приемы улучшения классификаторов: стекинг, бэггинг и бустинг.

Бэггинг (bagging) = Бутстреп + агрегация. Алгоритм "случайный лес" (random forest). Ключевые параметры модели. Ошибка Out-of-bag. Оценка информативности переменных (Importance). Классификация вин с помощью случайного леса. Анализ несбалансированных выборок. Определение числа деревьев. Библиотеки randomForest и ranger. 

Идея бустинга (boosting). Бустинг и разложение в ряд Тейлора. Алгоритм XGBoost. Регуляризация сложности модели. Библиотеки бустинга в R.

Простейшая версия стекинга  (stacking): блендинг. Классический стекинг. Выбор алгоритмов для стекинга. Особенности признакового пространства при стекинге алгоритмов. Параметры метаалгоритма.


## 12. Подготовка данных

Оценка точности классификации. Точность (accuracy) и ее проблемы в случае дисбаланса классов. Матрица ошибок (confusion table). Точность для заданного класса (precision) и полнота (recall) классификации для выбранного класса. Зоопарк метрик. F-мера. ТОчность классификации ирисов, caret::ConfusionMatrix.

Важность подготовки данных. Разметка данных. Пример подготовки данных на конкурсе от Beeline. Преобразование типов данных. Кодирование нечисловых признаков. Нормализация и стандартизация. Обработка выбросов. Учет пропусков/импутация. Feature engineering.

Соревнования по машинному обучению. Общедоступные наборы данных.


# Контрольные вопросы

1. Типы данных (статистические шкалы) и как они реализованы в R. Факторы.
2. Имена переменных R.
3. Векторы. Доступ к элементам. Создание/удаление.
4. Списки и таблицы. Доступ к элементам. Создание/удаление.
5. Класс и структура переменных. 
6. Построение графиков (plot).
7. Генеральная совокупность и выборка. 
8. Меры центральной тенденции: среднее, медиана. Влияние выбросов. 
9. Квантили. Функция summary. 
10. Меры разброса: дисперсия, стандартное отклонение, межквартильное расстояние.
11. Разведочный анализ данных — зачем он нужен. Основные функции R, используемые в разведочном анализе данных.
12. Гистограмма — как строится и для чего служит.
13. Загрузка табличных данных. Проверка на пропуски в данных. 
14. Диаграмма рассеивания и матрица диаграмм рассеивания. 
15. Боксплот (boxplot) — как строить и зачем нужен. 
16. Постановка задачи кластеризации. Где используется кластерный анализ. 
17. Сходство и отличие задач кластеризации и классификации. 
18. Геометрическая идея кластеризации. Расстояние между точками-объектами. 
19. Расстояние между кластерами. 
20. Задачи аналитика в кластерном анализе. Способы стандартизации переменных. Выбор расстояния между кластерами разных видов. Интерпретация результатов кластерного анализа.
21. Алгоритм иерархического кластерного анализа. Работа функции hclust.
22. Поиск кластеров на дендрограмме. График "каменистая осыпь".
23. Алгоритм k-средних. Особенности метода k-средних, его преимущества и недостатки. 
24. Выбор начального расположения центров кластеров. 
25. Определение числа кластеров k.
26. Математическая модель k-means. Внутрикластерная сумма квадратов.
27. Визуализация результатов кластерного анализа.
28. Понятие о статистической гипотезе. Виды и примеры гипотез. 
29. Алгоритм проверки статистических гипотез.
30. Нулевая и альтернативная гипотезы. 
31. Статистический критерий и статистика критерия. 
32. Уровень значимости $\alpha$. Область принятия гипотезы и критическая область. 
33. $p$-значение и его трактовки. 
34. Формулирование вывода по результатам проверки гипотезы. 
35. Односторонние и двусторонние статистические критерии. 
36. Ошибки 1-го и 2-го рода
37. Связь ошибок 1-го и 2-го рода с выбором уровня значимости.
38. Ковариация. Коэффициент корреляции Пирсона, его интерпретация. Функции для расчета корреляции в R.
39. Направления связи. Сила корреляции. 
40. Коэффициент корреляции и независимость переменных. 
41. Связанность и причинная обусловленность, типичные ошибки при изучении связи между двумя явлениями. 
42. Общая задача регрессии. Модель линейной регрессии. Простая линейная регрессия.
43. Поиск коэффициентов линейной регрессии. Метод наименьших квадратов.
44. Оценка качества регрессии (MSE, RMSE). 
45. Коэффициент детерминации $R^2$, его интерпретации.
46. Этапы линейной регрессии в R. Диагностика модели (summary). 
47. Уравнения многомерной линейной регрессии. 
48. Мультиколлинеарность, способы ее выявления. Tolerance и VIF. 
49. Выбор информативных переменных в многомерной линейной регрессии.
50. Теорема Гаусса-Маркова: ее условия, что она дает и последствия нарушения ее ограничений. Примеры нарушения условий теоремы Гаусса-Маркова.
51. Анализ остатков: проверка нормальности распределения. Коррекция моделей при отклонениях распределения остатков от нормального.
52. Анализ остатков: проверка постоянства дисперсий остатков.  
53. Анализ остатков: понятие рычага (leverage).
54. Прогноз, виды прогностических моделей. 
55. Чего следует ожидать от прогноза? Выявление аномалий.
56. Временной ряд. Примеры использования прогнозирования временных рядов. 
57. Составляющие временного ряда (тренд, сезонность, ошибка). Аддитивная и мультипликативная сезонность. Как превратить один вид сезонности в другой.
58. Прогнозирование на основе линейной регрессионной модели с сезонными (индикаторными) переменными. Порядок работы с временным рядом.
59. Порядок работы с временным рядом: к чему приводит смена характера ряда? Что делать с выбросами?. 
60. Ловушка индикаторных переменных и как с ней справляться.
61. Экспоненциальное сглаживание. 
62. Метод Холта-Уинтерса (Holt-Winters), модели с мультипликативной и аддитивной сезонностью. Локальный тренд, локальная сезонность.
63. Сравнение экспоненциального сглаживания и линейной регрессии в прогнозировании временных рядов.
64. Метрики ошибок прогноза. Оценка качества модели сравнением с базовой моделью, выбор метода прогнозирования.
65. Задача классификации. Ее сходство и отличия от задач кластеризации и регрессии.
66. Метод k ближайших соседей (kNN). Понятие ленивого обучения. 
67. Подготовка данных в kNN. 
68. Определение числа ближайших соседей. 
69. Задачи, в которых применяется kNN.
70. Проблема чрезмерной подгонки/переобучения (overfitting). 
71. Кроссвалидация (перекрестная проверка). Метод тестового множества.
72. Метод исключенных наблюдений (leave-one-out cross validation).
73. k-кратная кроссвалидация (k-fold кроссвалидация). 
74. Алгоритм построения дерева классификации и регрессии (CART). Представление дерева в виде набора логических правил. 
75. Элементы дерева: узлы, родители и потомки, листья. 
76. Разновидности метода деревьев: oblique trees, oblivious trees 
77. Как строить разделяющие гиперплоскости. Меры чистоты узла (impurity): индекс Джини, энтропия. 
78. Правила остановки обучения дерева.
79. Достоинства и недостатки деревьев классификации. Борьба с переобучением.
80. Приемы улучшения классификаторов: стекинг, бэггинг и бустинг.
81. Алгоритм бутстрепа.
82. Алгоритм "случайный лес" (random forest). Ключевые параметры модели.
83. Ошибка Out-of-bag в алгоритме "случайный лес". Оценка информативности переменных. 

